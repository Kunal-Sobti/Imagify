{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b537e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import PIL\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#downloading dataset:\n",
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "\n",
    "#Data processing:\n",
    "def normalize(input_image, input_mask):\n",
    "  \n",
    "    # Normalize the pixel range values between [0:1]\n",
    "    img = tf.cast(input_image, dtype=tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return img, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_train_ds(dataset):\n",
    "    img = tf.image.resize(dataset['image'], \n",
    "                          size=(width, height))\n",
    "    mask = tf.image.resize(dataset['segmentation_mask'],\n",
    "                           size=(width, height))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "\n",
    "    img, mask = normalize(img, mask)\n",
    "    return img, mask\n",
    "\n",
    "@tf.function\n",
    "def load_test_ds(dataset):\n",
    "    img = tf.image.resize(dataset['image'], \n",
    "                          size=(width, height))\n",
    "    mask = tf.image.resize(dataset['segmentation_mask'], \n",
    "                           size=(width, height))\n",
    "\n",
    "    img, mask = normalize(img, mask)\n",
    "    return img, mask\n",
    "\n",
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "\n",
    "# Batch size is the number of examples used in one training example.\n",
    "# It is mostly a power of 2\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "# For VGG16 this is the input size\n",
    "width, height = 224, 224\n",
    "\n",
    "train = dataset['train'].map(\n",
    "    load_train_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test = dataset['test'].map(load_test_ds)\n",
    "\n",
    "train_ds = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test.batch(BATCH_SIZE)\n",
    "\n",
    "#Visualizing data:\n",
    "def display_images(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', \n",
    "             'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for img, mask in train.take(1):\n",
    "    sample_image, sample_mask = img, mask\n",
    "    display_list = sample_image, sample_mask\n",
    "\n",
    "display_images(display_list)\n",
    "\n",
    "#U-Net:\n",
    "base_model = keras.applications.vgg16.VGG16(\n",
    "    include_top=False, input_shape=(width, height, 3))\n",
    "\n",
    "layer_names = [\n",
    "    'block1_pool',\n",
    "    'block2_pool',\n",
    "    'block3_pool',\n",
    "    'block4_pool',\n",
    "    'block5_pool',\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(\n",
    "    name).output for name in layer_names]\n",
    "base_model.trainable = False\n",
    "\n",
    "VGG_16 = tf.keras.models.Model(base_model.input,\n",
    "                               base_model_outputs)\n",
    "\n",
    "#defined decoder:\n",
    "def fcn8_decoder(convs, n_classes):\n",
    "    f1, f2, f3, f4, p5 = convs\n",
    "\n",
    "    n = 4096\n",
    "    c6 = tf.keras.layers.Conv2D(\n",
    "        n, (7, 7), activation='relu', padding='same', \n",
    "      name=\"conv6\")(p5)\n",
    "    c7 = tf.keras.layers.Conv2D(\n",
    "        n, (1, 1), activation='relu', padding='same', \n",
    "      name=\"conv7\")(c6)\n",
    "\n",
    "    f5 = c7\n",
    "\n",
    "    # upsample the output of the encoder\n",
    "    # then crop extra pixels that were introduced\n",
    "    o = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(\n",
    "        4, 4),  strides=(2, 2), use_bias=False)(f5)\n",
    "    o = tf.keras.layers.Cropping2D(cropping=(1, 1))(o)\n",
    "\n",
    "    # load the pool 4 prediction and do a 1x1\n",
    "    # convolution to reshape it to the same shape of `o` above\n",
    "    o2 = f4\n",
    "    o2 = (tf.keras.layers.Conv2D(n_classes, (1, 1),\n",
    "                                 activation='relu', \n",
    "                                 padding='same'))(o2)\n",
    "\n",
    "    # add the results of the upsampling and pool 4 prediction\n",
    "    o = tf.keras.layers.Add()([o, o2])\n",
    "\n",
    "    # upsample the resulting tensor of the operation you just did\n",
    "    o = (tf.keras.layers.Conv2DTranspose(\n",
    "        n_classes, kernel_size=(4, 4),  strides=(2, 2), \n",
    "      use_bias=False))(o)\n",
    "    o = tf.keras.layers.Cropping2D(cropping=(1, 1))(o)\n",
    "\n",
    "    # load the pool 3 prediction and do a 1x1\n",
    "    # convolution to reshape it to the same shape of `o` above\n",
    "    o2 = f3\n",
    "    o2 = (tf.keras.layers.Conv2D(n_classes, (1, 1),\n",
    "                                 activation='relu', \n",
    "                                 padding='same'))(o2)\n",
    "\n",
    "    # add the results of the upsampling and pool 3 prediction\n",
    "    o = tf.keras.layers.Add()([o, o2])\n",
    "\n",
    "    # upsample up to the size of the original image\n",
    "    o = tf.keras.layers.Conv2DTranspose(\n",
    "        n_classes, kernel_size=(8, 8),  strides=(8, 8),\n",
    "      use_bias=False)(o)\n",
    "\n",
    "    # append a softmax to get the class probabilities\n",
    "    o = tf.keras.layers.Activation('softmax')(o)\n",
    "    return o\n",
    "\n",
    "#combining everything:\n",
    "def segmentation_model():\n",
    "\n",
    "    inputs = keras.layers.Input(shape=(width, height, 3))\n",
    "    convs = VGG_16(inputs)\n",
    "    outputs = fcn8_decoder(convs, 3)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model = segmentation_model()\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Creating prediction mask utility:\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display_images([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display_images([sample_image, sample_mask,\n",
    "                        create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
    "\n",
    "\n",
    "show_predictions()\n",
    "\n",
    "#Training\n",
    "EPOCHS = 20\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_ds, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_ds)\n",
    "\n",
    "#Metrics:\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    '''\n",
    "    Computes IOU and Dice Score.\n",
    "\n",
    "    Args:\n",
    "      y_true (tensor) - ground truth label map\n",
    "      y_pred (tensor) - predicted label map\n",
    "    '''\n",
    "\n",
    "    class_wise_iou = []\n",
    "    class_wise_dice_score = []\n",
    "\n",
    "    smoothening_factor = 0.00001\n",
    "\n",
    "    for i in range(3):\n",
    "        intersection = np.sum((y_pred == i) * (y_true == i))\n",
    "        y_true_area = np.sum((y_true == i))\n",
    "        y_pred_area = np.sum((y_pred == i))\n",
    "        combined_area = y_true_area + y_pred_area\n",
    "\n",
    "        iou = (intersection + smoothening_factor) / \\\n",
    "            (combined_area - intersection + smoothening_factor)\n",
    "        class_wise_iou.append(iou)\n",
    "\n",
    "        dice_score = 2 * ((intersection + smoothening_factor) /\n",
    "                          (combined_area + smoothening_factor))\n",
    "        class_wise_dice_score.append(dice_score)\n",
    "\n",
    "    return class_wise_iou, class_wise_dice_score\n",
    "\n",
    "#model prediction with metrics:\n",
    "def get_test_image_and_annotation_arrays():\n",
    "    '''\n",
    "    Unpacks the test dataset and returns\n",
    "    the input images and segmentation masks\n",
    "    '''\n",
    "\n",
    "    ds = test_ds.unbatch()\n",
    "    ds = ds.batch(info.splits['test'].num_examples)\n",
    "\n",
    "    images = []\n",
    "    y_true_segments = []\n",
    "\n",
    "    for image, annotation in ds.take(1):\n",
    "        y_true_segments = annotation.numpy()\n",
    "        images = image.numpy()\n",
    "\n",
    "    y_true_segments = y_true_segments[:(\n",
    "        info.splits['test'].num_examples - (info.splits['test']\n",
    "                                            .num_examples % BATCH_SIZE))]\n",
    "    images = images[:(info.splits['test'].num_examples -\n",
    "                      (info.splits['test'].num_examples % BATCH_SIZE))]\n",
    "\n",
    "    return images, y_true_segments\n",
    "\n",
    "\n",
    "y_true_images, y_true_segments = get_test_image_and_annotation_arrays()\n",
    "\n",
    "integer_slider = 2574\n",
    "img = np.reshape(y_true_images[integer_slider], (1, width, height, 3))\n",
    "y_pred_mask = model.predict(img)\n",
    "y_pred_mask = create_mask(y_pred_mask)\n",
    "y_pred_mask.shape\n",
    "\n",
    "\n",
    "def display_prediction(display_list, display_string):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        if i == 1:\n",
    "            plt.xlabel(display_string, fontsize=12)\n",
    "        plt.imshow(keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "iou, dice_score = compute_metrics(\n",
    "    y_true_segments[integer_slider], y_pred_mask.numpy())\n",
    "display_list = [y_true_images[integer_slider],\n",
    "                y_true_segments[integer_slider], y_pred_mask]\n",
    "\n",
    "display_string_list = [\"{}: IOU: {} Dice Score: {}\".format(class_names[idx],\n",
    "                                                           i, dc) for idx, (i, dc) in\n",
    "                       enumerate(zip(np.round(iou, 4), np.round(dice_score, 4)))]\n",
    "display_string = \"\\n\\n\".join(display_string_list)\n",
    "\n",
    "\n",
    "# showing predictions with metrics\n",
    "display_prediction(display_list, display_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
